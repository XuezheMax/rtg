model_args:
  dropout: 0.1
  ff_size: 512 # change to 2048
  hid_size: 256  # change to 512
  n_heads: 4    # change to 8
  n_layers: 3   # change to 6
  src_vocab: 8000
  tgt_vocab: 8000
  tied_emb: three-way
model_type: tfmnmt
optim:
  args:
    betas:
    - 0.9
    - 0.98
    eps: 1.0e-09
    label_smoothing: 0.1
    lr: 0.1
    warmup_steps: 4000
  name: ADAM
prep:
  max_types: 500  # change to 8000
  pieces: bpe
  shared_vocab: true
  src_len: 100
  tgt_len: 100
  train_src: data/train.src
  train_tgt: data/train.tgt
  truncate: true
  valid_src: data/valid.src
  valid_tgt: data/valid.tgt
tester:
  decoder:
    beam: 4
    max_len: 150
  suit:
    valid:
    - data/valid.src
    - data/valid.tgt
trainer:
  batch_size: 4   # change to 96
  check_point: 100  # change to 1000 or 2000
  keepmodels: 10
  steps: 2000   # change to 128000 or up
updated_at: '2019-03-09T21:15:33.707183'
